import json
import pandas as pd
import sys
import glob
import os

def load_trace(file_path):
    """
    Loads a Chrome Trace JSON file generated by torch.profiler.
    """
    print(f"Loading trace: {file_path}...")
    try:
        with open(file_path, 'r') as f:
            trace = json.load(f)
    except json.JSONDecodeError:
        print("Error: Failed to decode JSON. The trace file might be incomplete.")
        return None
    
    # PyTorch traces sometimes wrap events in a top-level dictionary
    if isinstance(trace, dict) and 'traceEvents' in trace:
        return trace['traceEvents']
    elif isinstance(trace, list):
        return trace
    else:
        print("Error: Unknown trace format.")
        return None

def analyze_kernels(events):
    """
    Aggregates duration by kernel name to find bottlenecks.
    """
    kernel_data = []
    
    for event in events:
        # PyTorch GPU kernels usually have category 'kernel' or 'gpu_user'
        # 'dur' is duration in microseconds
        if event.get('cat') in ['kernel', 'gpu_user'] and 'dur' in event:
            kernel_data.append({
                'name': event.get('name', 'Unknown'),
                'duration_us': event.get('dur', 0),
                'ts': event.get('ts', 0)
            })

    if not kernel_data:
        print("No GPU kernel events found. Did you enable usage=True in the profiler?")
        return None

    df = pd.DataFrame(kernel_data)
    
    # 1. Total GPU Time
    total_gpu_time_ms = df['duration_us'].sum() / 1000
    
    # 2. Group by Kernel Name
    summary = df.groupby('name')['duration_us'].agg(['count', 'sum', 'mean']).reset_index()
    summary['sum_ms'] = summary['sum'] / 1000
    summary['mean_ms'] = summary['mean'] / 1000
    summary = summary.sort_values(by='sum', ascending=False)
    
    # 3. Calculate % Contribution
    summary['%_total_time'] = (summary['sum_ms'] / total_gpu_time_ms) * 100

    return summary, total_gpu_time_ms

def main(trace_folder="results/traces"):
    trace_files = glob.glob(os.path.join(trace_folder, "*.json"))
    if not trace_files:
        print(f"No .json trace files found in {trace_folder}")
        return

    print(f"{'='*60}")
    print(f" Profiler Trace Analysis")
    print(f"{'='*60}")

    for trace_file in trace_files:
        events = load_trace(trace_file)
        if not events:
            continue
            
        print(f"\nAnalyzing: {os.path.basename(trace_file)}")
        results = analyze_kernels(events)
        
        if results:
            summary_df, total_time = results
            
            print(f"Total GPU Kernel Time: {total_time:.2f} ms")
            print("-" * 60)
            print(f"{'Kernel Name':<50} | {'Calls':<8} | {'Total (ms)':<10} | {'% Time':<8}")
            print("-" * 60)
            
            # Print top 10 bottlenecks
            for _, row in summary_df.head(10).iterrows():
                name = row['name'][:47] + "..." if len(row['name']) > 47 else row['name']
                print(f"{name:<50} | {int(row['count']):<8} | {row['sum_ms']:<10.2f} | {row['%_total_time']:<8.1f}")
            print("-" * 60)
            
            # Export analysis to CSV
            out_file = trace_file.replace('.json', '_analysis.csv')
            summary_df.to_csv(out_file, index=False)
            print(f"Saved analysis to {out_file}")

if __name__ == "__main__":
    # If a specific file is passed, use it, otherwise search default folder
    if len(sys.argv) > 1:
        path = sys.argv[1]
        if os.path.isdir(path):
            main(path)
        elif os.path.isfile(path):
            events = load_trace(path)
            if events:
                analyze_kernels(events)
    else:
        main()